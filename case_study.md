# **The Computer Memory System, Memory Hierarchy, and Cache Design**

Table of contents:
1. [Introduction](#Introduction)
2. [An Analysis of Modern Literature and Key Concepts in the Memory System, Memory Hierarchy, and Memory Caches](#an-analysis-of-modern-literature-and-key-concepts-in-the-memory-system-memory-hierarchy-and-memory-caches) 
3. [Important Challenges and Advancements in the Modern Memory System](#important-challenges-and-advancements-in-the-modern-memory-system) 
4. [Modern Applications of the Memory System](#modern-applications-of-the-memory-system) 
5. [Conclusion](#conclusion) 
6. [References](#references)
## **Introduction**

When the general public pictures a computer, often the first thought that comes to mind is along the lines of a machine that can perform logic. With a slightly more informed background, that is still unfamiliar with computer architecture, they may picture a system that distils complex problems into small sequential steps of binary that are handled to solve the larger problem; one may even picture the machine as a means of using this system to transform inputs to outputs. 

While these conceptualizations of computers are largely correct, they ignore the fundamental importance of memory. The logic processors that a computer is known for are wholly useless without a means of storing and transferring the data that it processes; similar to an oil refinery plant without any pipelines, barrels, or other storage containers, amounting to an impressive feat of inactive engineering next to a puddle of raw crude oil. Within a computer, these storage units can be separated into two groups: 1) memory systems, which act as a working area for data being currently operated on, and 2) storage systems, which act as long term consistent data storage. The focus of this case study is on memory systems, specifically memory hierarchy and cache design. 

This case study will begin with a comprehensive analysis and discussion of key concepts covered in modern memory system literature. This includes a short history of computational memory, the role of memory in the computer system, key concepts guiding memory system architecture (e.g. caching and the memory hierarchy), and the individual components that make up the memory system (e.g. DRAM and SRAM). The case study then discusses some challenges faced by modern memory systems given the key concepts that govern their organisation and also discusses advancements that seek to address these challenges. Lastly, the case study will take a higher level examination at memory systems in two relevant areas to INFR 2810 students: applications in programming, and memory in a separate computing component: the GPU.  

## **An Analysis of Modern Literature and Key Concepts in the Memory System, Memory Hierarchy, and Memory Caches**

This section of the case study serves to review mainstream memory system literature in analysing and explaining the core concepts related to computer memory systems. It begins with a short history, then explains the relationship between the computer and memory, followed with an in-depth explanation of key memory concepts based on academic material published by important modern memory systems researchers.

### A Short History
Humans handle information quite easily: whether in the form of thoughts, speech, writing, symbols, etc. Until and into the 17th and 18th century, this has allowed for humans to make drastic advances in multiple disciplines over time. However, when humans began inventing machines that were meant to take in some form of input and process it using standardized logical systems, a new approach to representing information for use by these systems was required. 

In 1833, this took the form of a punch card which was inserted into an machine called the Analytical Engine, invented by Charles Babbage. This machine would represent information as a pattern of holes that were punched into a card in specific patterns. Almost 100 years later, in 1932, a new approach was invented by Gustav Tauschek, where information was represented as magnetised materials that were written on the drum as it spun (similar to the modern hard drive disk) to read and write. Between then and into the 1950s information continued to be represented using similar forms of magnetic representation, with improvements as to how the information was arranged, accessed, and written; such as Jay Forrester's representation of memory on a grid. It was not until the late 1950s and 1960/70s until the modern representation of data as electrical currents on transistors first appeared. At this time is when the modern SRAM (Static Random Access Memory) and DRAM (Dynamic Random Access Memory) memory technologies were invented `[1],[2]`.

### Memory and Computing
Data storage serves a core function in the modern computing system (see figure below). It's main purpose is to store data that is sent to and from the processing components of the computer. As explained in the introduction, storage can be broken down into two distinct components, the working data space (memory) and the longer-term non-volatile (data is held when computer is powered-off) storage space.  
![image](https://github.com/user-attachments/assets/f08d5ecb-6f00-48d6-b9e4-1976f7952a54)

At its most fundamental level, memory units need to store data for immediate use by the processor. Much like we have seen in CPU lessons throughout this course, data is stored in the memory in a binary format, represented by 0s and 1s. This brings up several key concepts to understand when discussing memory:
1. Capacity: The total amount of data the memory unit can hold
2. Addresses: Individual spaces in the memory. There is one address for every unit of data in the memory. In total, the number of addresses in the memory corresponds to the capacity (this is known as the address space). 
3. Measures of performance:
	1. Latency: How long it takes the processor to access data from the memory 
	2. Bandwidth: How much data can the processor access from the memory
	3. Parallelism: How many accesses can be made by the processor to the memory at any one moment in time   
	- To better understand these measures of performance, `[3]` provides us with the following formulas which put into context how much data the processor can access from the memory per unit of time:  
		`Bandwidth (accesses/time) = Parallelism (addresses accessed at a time) / Latency (time per access)`;  
		or,  
		`Bandwidth (bytes/time) = Parallelism (addresses accessed at a time) / Latency (time per access) * data size (bytes per access)`    

Given that the goal of a computer is to solve problems, and that greater capacity and performance can result faster or more complex problem solving, then the goal of any computer architect is in maximizing the capacity (the size of data stored, and consequently maximum problem size it can handle) for the computer's memory system while also maximizing the performance (allowing data relevant to the problem to be processed by the CPU faster). This goal has resulted in an important innovation to the memory system of a computer: the cache. The cache is meant to act as a memory unit in the computing system to complement the main memory unit. It is a smaller unit of memory that is meant to hold data that the CPU needs to access more quickly than it would be able to access the main memory unit. This concept of complementing units of memory to optimize performance brings up a core concept to memory in the computing system, the memory hierarchy `[3]`. 

### The Memory Hierarchy
As previously discussed, the computer has multiple units that store data. In this case study, we divided these units into a conceptually important split of memory vs storage. Before discussing the memory hierarchy, its important to outline the philosophy behind that distinction. Specifically, these two categories of data storage are not wholly separate, but a hierarchical abstraction of each other. Data is first introduced to the computer by being saved to the storage device (e.g. HDD, SDD), whenever the CPU needs to process that data, it is transferred from the storage device into the memory system of the computer. Importantly, not all the data from the storage device is  moved to the memory system. An immediate question may be: "why not store all the data from the storage unit in the memory system so that it can be rapidly accessed?" That is principally because computer architects intentionally designed the memory system to not hold as much data at the storage system. Recalling the principal objectives in designing a computing memory system: capacity and performance. While having a large unit of memory to replace the storage device would greatly improve the capacity of the memory system, it would drastically reduce the performance by increasing the sheer size of the memory system that needs to be traversed. 
	Additionally, and of equal importance, are the cost considerations and technological/physical constraints that come into play when trying to increase the memory (RAM) size[3]; however, in this section we are focusing on the abstractive nature of memory/storage layers.
As a result, the main memory unit (RAM) inside a memory system was designed to act as a layer in the computing system that is smaller than the storage unit and retrieves data from the storage unit only when it is specifically required by the processor. The basic philosophy here is to separate data that is immediately required by the CPU from data that it does not need to access immediately, with the more urgent data existing in some state that is more easily accessible by the processor. This philosophy does not end at the storage-memory divide, it is reduplicated many times throughout the memory system of a computer to continuously make more urgent data more easily available to the processor. This brings us back to the concept introduced in the previous section, the cache memory unit. The cache memory unit is an example of this data abstraction within the memory system required by processing-urgency; where the cache stores urgent data from the main memory unit in a state that is more accessible to the processor than in the main memory unit. The entire storage and memory system within a computer and their relationships to each other can be explained using this philosophy into what is called the memory hierarchy (see figure below). `[3],[4]`   

![image](https://github.com/user-attachments/assets/13840da7-a5ae-4c9a-96d7-c46b7baa9ef8)  

    Figure: memory hierarchy. Nicholas Poulin, 2024. Note the storage device is not explicitly a part of the memory hierarchy, as it exists separate from the memory system.  
		
Within the memory hierarchy that describe the memory system are the three caches and the main memory unity. Caches are named in an L# format, with the L standing for "level" and the number denoting their hierarchy in an ascending order (1 being at the top with the lowest latency). The hierarchy is ordered by how fast they are, i.e. the latency (as described in the Memory and Computing section's performance metrics). Contrastingly, the capacity decreases as you go up the hierarchy and increases as you go down, with the main memory holding the greatest capacity and slowest latency versus the L1 cache having the lowest capacity and fastest latency.

The memory hierarchy is not solely a means of describing characteristics of units in the memory system. It also plays a crucial role in how the processor interacts with the memory. Whenever the processor accesses the memory system, it does so in a sequential order, starting at the top level in the memory hierarchy and moving down to the next lower level if the address is not found in the top level. When the processor addresses the memory and finds a match, it is referred to as a "hit" and the data is served on the spot; whereas if it is not found and needs to move down a level, it is referred to as a "miss" and it moves down a level. Due to the increase in capacity per unit as you move down in the memory hierarchy, the chance of hitting any given address increases. Based on these behaviours, and the fact that a hit is guaranteed if the main memory unit is accessed (assuming the address has data in the memory and it is not a null pointer), the below latency formula from `[3]` integrates the memory hierarchy into our latency calculation:  
![image](https://github.com/user-attachments/assets/70e74953-4809-48cc-bdae-019a8920e5a7)  

This formula is essentially an implementation of the Expected value formula, represented by **E(X)=∑xP(x)**. Denoting that this models the average latency given our hit probabilities and an assumption of 3 levels of caching (note there can be more or less) where each level has an increasing hit probability thanks to its larger capacity.

With this equation we can start to imagine how an architect or programmer can reduce the latency of whatever instructions they want the computer to process. Mainly, by increasing the probability of a hit at the higher level caches (remember: higher level refers to a lower number, L1 being the highest level). This introduces two key principles outlined in all bodies of comprehensive modern memory literature `[3] - [5]` that are utilized to minimize the latency whenever the processor addresses the memory system, locality:
1. **Temporal Locality**: If data at a specific address is referenced, then it will tend to be referenced again soon.  
2. **Spatial Locality:** If data at a specific address is referenced, then nearby addresses are likely to be referenced soon as well.
These principles govern much of how a memory system is managed, governed, and interacted with.

Lastly, it is important to touch on common cache organization. Generally speaking, the L1 cache, as the lowest latency component in the memory system, is typically allocated to every individual core in a processor. L2 cache is generally also placed on the processor and can be, but not always, allocated to a single core. L3 cache implementations generally exist outside the CPU and is shared by multiple processors. Actual implementation of caching can differ substantially by computer. 

### DRAM vs. SRAM, Cache vs. Main Memory
When determining how to implement a unit within a memory system, an important decision is the *physical substrate* that it implements. In modern memory systems, DRAM and SRAM are the most two primarily used substrates. The difference between these two types are the result of differing optimizations based on the same set of technological constraints they must navigate. SRAM implements a structure that results in faster latency and lower capacity, whereas DRAM implements a greater capacity at the expense of a lower latency. As such, caches utilize the SRAM substrate and the main memory unit implements DRAM substrate.

#### SRAM and the Cache
The SRAM has a faster latency when communicating to the processor because of its composition. An SRAM memory unit (e.g. a cache) is composed of SRAM cells. Each cell is composed of 6 transistors which are of the same type of semiconductor-based transistor as the processor (allowing for its rapid communication with the processor). A cache implementing SRAM can be broken down into cache blocks. These blocks are groupings of SRAM cells that hold data and are given a tag that holds the address and some information about the block for the processor to reference (these blocks are typically of 64 byte size). Caches are are then mapped to same-sized chunks in the memory system address, where a mapping can occur between the block and memory in one of varying types, such as: fully associative and direct mapped. These differing relationships have trade offs, with less direct relationships resulting in a greater utilization of space but requiring more time to address (as multiple blocks can be mapped to one chunk). An important article in memory system literature was published in 1989 `[6]` which introduced set-associative mapping, acting as a combination of both methods where blocks are grouped into sets of a specified number of blocks. This allows for greater utilization compared to direct mapping, but allows not having to search every block in a cell as only N-specified blocks belong to the set mapped to the address in memory. 

It is important to note that because of the SRAM structure using the same semiconductor structure as the processor, it is placed on the same semiconductor as the processor, allowing for lower latency.

#### DRAM and the Main Memory

![image](https://github.com/user-attachments/assets/d6443ce5-3edd-4cb7-b63c-cbf5c12af8eb)  

	Figure: A Corsair DDR2-533 RAM module. Retrieved from: https://commons.wikimedia.org/wiki/File:DRAM_DDR2_512.jpg  

DRAM implements a structure resulting in greater capacity for better-than-storage-unit but worse-than-cache latency. This is achieved through a cell structure (DRAM cells) where each cell is composed of one transistor and one capacitor. Because only 1 (compared to SRAM's 6) transistors are required, many more cells can occupy the same space as an SRAM cell, resulting in greater capacity`[3]`. 

Due to its differing structure, the DRAM exists separate from the processor semiconductor, in its own DRAM chip that is connected to the processor via electrical wires that make up the memory bus, which itself is composed of an address bus, command bus, and data bus (as noted in previous CPU documentation for this course).

Banks are logically structured in the form of channels > ranks > chips > and banks, within each of which the components can run parallel. 8 banks make up one chip, 8 chips make up one rank, and a channel is composed of all the ranks that share the same memory bus. Therefor, different channels can run parallel to each other on their differing memory buses, whereas groupings that belong to the same channel must transmit via the bus sequentially. Banks are organized in a 2-D array structure, where each row-column combination corresponds to a DRAM cell `[3]`. Note that SRAM is organized into a similar 2D array structure.

An other important concept to note is the refresh interval. Due to the structure of DRAM cells, electrical charges are lost over time. To avoid losing data, DRAM cells must be refreshed every so often (e.g. 64ms ), where data is re-written to its cell. During this refresh, the cell cannot be accessed. The re-writing process is another reason why SRAM is faster, as their 6-transistor structure does not lead to the loss exhibited in DRAM, thus not requiring costly re-writes.`[3]` 

### Main Memory, Multiple Caches, and their Interaction
The last concept to cover on caches is in the implementation of multiple caches. Examples in this case study have used a common layout of 3 levels of caches (L1-L3). The main memory, as the foundation of the memory structure, holds all memory data; that is, all caches are some subset of memory in the main DRAM component. However, the relationship between caches can differ. Caches can either implement: 1) inclusive policy (where a higher level cache is the subset of its lower level cache), 2) exclusive policy (where caches share no data), or 3) non-inclusive (where a cache may contain a subset of its lower level cache) `[3]`. 

Due to the subset nature of higher to lower memory hierarchy levels, some policy must exist to update lower level memory when data in the higher level cache is updated by the processor (recall that the processor will stop addressing memory as soon as it hits, so there is no need for the processor to interact with main memory when data is in a cache). The first option is the write-through policy, where any change is immediately updated through to lower-level memory. This results in consistent data, but can be slower as every update requires writing back. The other policy, write-back, only updates lower level memory when the data is evicted from the cache. To track this discrepancy between hierarchy levels, a flag is amended to the cache to signal it needs to be back-propagated `[3]`.

Lastly, it is important to note that caches are sometimes partitioned to include both instruction data and data data, where each partition in a cache only stores one of the two data types. This is primarily only done at the highest level cache, as it is purposely placed closest to the instruction-reading engine within the processor `[3]`. 

### Virtual vs Physical Memory
The computer does not actually expose its physical memory addresses to any program that runs above the operating system. It does so to avoid issues of programs overwriting the data of other programs that are running simultaneously (as no program would be able to tell that it is writing over space in memory currently under use, at least in an efficient manner). As such, the operating system creates what is called a "virtual memory" which is then mapped onto the physical memory so that programs can manager their memory usage without having to worry about overwriting other programs in the memory system. The mapping of virtual to physical memory is done on an on-demand basis (mapped to physical when the program accessing memory is actually ran). The operating system then stores that mapped virtual to physical relationship in a "page table" (named due to how memory is split into chunks referred to as "pages", in the table a "virtual page" is mapped to a "physical page" of equal size) `[3]`. 

A problem arises when there is no more physical space for a new virtual page to be mapped to. In this case, the operating system will act based on its page replacement policy, finding an existing physical page that it deems as unlikely to be accessed in the near future (i.e. on the main memory unit and not in any cache), and then removing it, referred to as page eviction. The physical page being removed is then saved back to the storage unit (if the data has changed since reading into memory), evicted, and the new virtual page to physical page is recorded in the page table. An important issue in modern memory systems literature arises in the case when a program has to consistently perform these page evictions, referred to as thrashing. In this case, the memory has been exhausted and evictions + replacements have to be performed frequently, greatly increasing the latency of the program as it has to frequently draw memory from the storage unit`[3] - [5]`. 

## **Important Challenges and Advancements in the Modern Memory System** 

#### Challenges in Modern Memory Caches
In this case study we will analyse two modern challenges related to caching in the memory system: inefficient cache utilization driven by modern cache management, and challenges to managing lower-level caching in multi-core processors.

Most memory caches try to implement a system where the most used data is stored in the highest hierarchy level caches. However, a barrier in this system is the practice of always writing the most recently accessed data into the cache. This is an issue as it often results in the caching of data that does not need to be accessed that frequently, in place of data that would make better use of the cache space. This is a complex issue to solve, as at such a low level in the computer, it is impossible to implement the required complexity in a smart allocation system that only allocates data that will be frequently accessed over the course of a program in the cache. There is a wide body of research that looks towards optimising the caching system. For an example of one solution, we look towards a 2007 paper `[7]` that proposes a an alternative set of policies for the cache insertion policy. This paper proposes placing new data into the least recently used position of a cache instead of the most recently used position. This policy is a complement to the previous LRU policy, allowing for one of the two policies to be used at any given time depending on which is more efficient for the current cache usage. 

Another challenge in modern caches is in how to manage caches and the caching process with computer systems that utilize multiple core processors. While the challenges faced by caching due to multi-core processors is extensive, this case study will solely focus on the challenge faced by the lowest hierarchical level cache. This lowest level cache will be shared by all of the cores in a processor. The issue then arises regarding how to ensure that each processor maintains appropriate cache utilization, avoiding scenarios where one processor continuously overwrites the data required by other processors. An example of how researchers look to solve this challenge using modern architecture can be seen in a 2004 paper `[8]` where partitioning of the lower level cache (L2) is proposed. In this system, the cache would be efficiently partitioned into partitions for each processor core, so that each core has the appropriate cache space it needs without interfering with data stored in the cache that is required by other processors.

#### More Multi-Core Challenges, in Main Memory
Multi-core processors are leading to similar issues in the main memory component of memory systems as exist in the cache. For example, in how cores interact with the main memory component: sometimes impeding on the access to memory of other cores. In these systems, not every core can access the main memory at the same time. As a result, it is important to ensure cores have adequate access and any few cores do not dominate main memory access to the detriment of the efficiency of the entire memory system. Modern memory literature has proposed many ways to optimise main memory scheduling, such as the ATLAS memory scheduling policy introduced in 2010 `[9]`. The ATLAS approach proposes ordering the threads (individual cores) by volume of service they have received from the main memory and to then prioritise cores that have had the least service. With certain workload distribution assumptions, this approach can result in significant reductions in the stalling periods experienced by the cores, as no individual cores are kept at an outsized low service volume. One can extend the core concepts of this approach to solving bottleneck problems in any system, such as a production line, where the slowest component of the line will dictated the fastest pace at which the production line can produce. In the ATLAS approach, focus is always paid attention to the core that has received the least frequent main memory service in an attempt to alleviate any bottlenecks cause by over-looked cores.

#### DDR5 RAM, Addressing the Memory Needs of Modern multi-core CPUs
In recent years, the core count on CPUs has increased almost exponentially. While modern memory system technology has done a good job at providing bandwidth to these additional cores to enable multi-core CPUs to achieve greater computing power, the bandwidth per core has been relatively constant over time`[10]`. 

In 2019, Micron introduced the latest innovation to the DDR RAM design, DDR5. This design structure will serve a crucial role in modern computing, where increasingly core-dense CPUs will become bottlenecked by bandwidth constraints of previous DRAM technology like DDR4. DDR5 not only allows for an implementation of RAM with a a greater mega transfer rate (MT/s, a measure of the data transfers performed between RAM and CPU per seconds; in DDR technology this is equal to 2 `*` the RAM clock frequency due to DDR transfers occurring on both rising and falling edges of a clock cycle) range than DDR4 (3200-6400 mega transfers per second vs 1600-3200), but for greater bandwidth at each mega transfer rate. To illustrate, DDR5 is able to achieve 2.85 GB/s bandwidth with 3200 MT/s to a 64 core CPU, compared to a rate of 2.10 GB/s in DDR4. DDR5 with a higher 6400 MT/s rate to a 64 core CPU can achieve a bandwidth as high as 4.66 GB/s `[10]`. 

DDR5 makes use of a number of technological innovations to achieve this greater transfer rate. However, many of these technologies are out-of-scope for this case study. Most relevant are the increased mega transfer rate and capacity that result from DDR5's ability to achieve a greater DRAM cell density. This not only gives the entire memory system a larger capacity base memory unit to work from, but allows for much greater capacities to the maximum amount of RAM that is implementable by any given computer`[10]`.

Taking into account the exponential growth we are currently experiencing in data availability, processing power, and data needs; continued advancements in existing RAM architecture such as DDR5 will be crucial in allowing computer systems advancements in other areas without being  bottlenecked as frequently by memory system limitations.

## **Modern Applications of the Memory System**
### Low Level Memory System Implications in Everyday Programming
One of the most fundamentally important programming skills is in understanding how to apply the most relevant tools to any given problem. This manifests most clearly in the programmer's selection of algorithms and data structures. While most skilled programmers are told the benefits of different data structures, their low-level implementation is rarely understood. 

For example, arrays and linked lists are some of the most used data structures in modern programming. To simplify, it is well known that arrays are used where reading data is more frequent and linked lists where writing is more frequent. However, most do not know why that is the case, specifically at a the memory system level. Through understanding the concepts discussed in this case study, the programmer will better understand why this is the case. This is because of the principles of locality. Arrays directly make use of the spatial locality principle that governs modern memory. That is, that when one address is accessed, nearby addressed will also be accessed. At a low level this results in the memory system optimizing for the addressing of these data addresses, and would place them in a higher location within the memory hierarchy, resulting in a faster latency when reading other elements within the array list. Whereas, for a linked-list, it is possible that  memory addresses that contain the next list element will never be cached due to their location in memory not being sequential, requiring latency-expensive addresses to the main memory. With this knowledge, programmers can optimise their use of data structures through making use of structures that implement locality principles. 

### The Importance of Memory Systems in GPUs and their Use in Key Technologies
In recent years, vast sums of resources and research have been allocated to the field of artificial intelligence. The computational requirements of these new technologies are vast, and opposed to more traditional algorithms, fundamentally rely on the GPU component of a computer for their processing. Some of the most popular and growing areas where this is the case are Large Language Models and Computer Vision, each of which require the processing of tensors, mathematical objects that are most efficiently processed by the GPU. 

The actual architecture of a GPU memory system is out of scope for this case study, however the core memory system concepts discussed here are core to the memory systems of a GPU as well, such as the use of a main memory component, cache levels, and memory hierarchy `[11]`. Due to these similarities, many of the challenges faced by CPU memory systems exist in GPU memory systems as well. Given our planet's finite resources, both in the form of material, technological, and energy inputs; academic advancements to the memory system will be essential in tapping the potential benefit to humanity provided by these GPU-intensive technologies.

![image](https://github.com/user-attachments/assets/4cd1e211-be95-41a4-b19b-2c79c4b6f427)

	Figure: Nvidia GeForce RTX 4090 GPU with the VRAM is represented by the red-highlighted cells that surround the main central NVIDIA chip. Retrieved from: https://commons.wikimedia.org/wiki/File:Nvidia@5nm@AdaLovelace@AD102@GeForce_RTX_4090@S_TW_2324A1_U2F028.MOW_AD102-301-A1_DSCx3@VIS.jpg 
	  

## **Conclusion**

Modern society has an ever increasingly important reliance on our computational systems. From the systems that are used to operate our essential infrastructure to the systems that are powering advancement in advanced technologies such as artificial intelligence. As this study has outlined, the memory system is a fundamental component of every one of these computer system. 

In designing modern memory systems, architects must be familiar with the core concepts that outline memory design. From the memory hierarchy, the choice of substrate in implementing a memory component, to the trade off between latency and capacity at the cache level. Further research in the memory system field will be essential in lessening the bandwidth limitations imposed by existing memory architecture in order to optimise our use of complex multi-core processing units. Aside from architects, it is important for those who most frequently make use of memory systems, programmers, to understand the memory implications for the computer instructions generated by their programs. 

To return to our opening oil manufacturing analogy: a crude oil oil refinery is useless without a robust system to handle the oil as it is inputted to, stored throughout, and outputted from the system. For a computing system, this efficient handling of inputs and outputs in the form of electronic data is equally important, and researching methods to optimise this process will be key to further advances in all areas of computing. 


## **References**

`[1]` J. P. Eckert, "A survey of digital computer memory systems," in _Proceedings of the IEEE_, vol. 85, no. 1, pp. 184-197, Jan. 1997, doi: 10.1109/5.554218

`[2]` Old Dominion University, “History of Computer Memory,” _www.cs.odu.edu_. https://www.cs.odu.edu/~tkennedy/cs300/development/Public/M01-HistoryOfComputerMemory/index.html

`[3]` Y. Kim and O. Mutlu, _Computing Handbook, Third Edition : Computer Science and Software Engineering_ Part 2, Chapter 18: Memory Systems . Philadelphia, PA: CRC Press, 2014.

`[4]` D. A. Patterson and J. L. Hennessy, Computer Organization and Design : the hardware/software interface, 6th ed. Amsterdam ; Boston: Elsevier/Morgan Kaufmann, 2020, pp. 900–1147.

`[5]` B. Jacob, S. Ng, and D. T. Wang, _Memory systems : cache, DRAM, disk_. Burlington, Ma: Morgan Kaufmann Publishers, 2010.

`[6]` M. D. Hill and A. M. Smith, “Evaluating associativity in CPU caches,” IEEE Transactions on Computers, Dec. 1989, doi: https://doi.org/10.1109/12.40842.

`[7]` M. K. Qureshi, A. Jaleel, Y. N. Patt, S. C. Steely, and J. Emer, “Adaptive insertion policies for high performance caching,” Jun. 2007, Abstract only, doi: https://doi.org/10.1145/1250662.1250709.

`[8]` S. Kim, D. Chandra, and Y. Solihin, “Fair Cache Sharing and Partitioning in a Chip Multiprocessor Architecture,” International Conference on Parallel Architectures and Compilation Techniques, pp. 111–122, Sep. 2004, doi: https://doi.org/10.5555/1025127.1026001.

`[9]` S. Schlachter and B. Drake, "Introducing Micron® DDR5 SDRAM: More Than a Generational Update",  XP055844818, May 2019.

`[10]` Y. Kim, D. Han, O. Mutlu, and Mor Harchol-Balter, “ATLAS: A scalable and high-performance scheduling algorithm for multiple memory controllers,” CiteSeer X (The Pennsylvania State University), Jan. 2010, Abstract only, doi: https://doi.org/10.1109/hpca.2010.5416658.

`[11]` A. Burnes, “A Deeper Look At VRAM On GeForce RTX 40 Series Graphics Cards,” NVIDIA, May 18, 2023. https://www.nvidia.com/en-us/geforce/news/rtx-40-series-vram-video-memory-explained/ (accessed Jul. 21, 2024).

_Where not explicitly stated otherwise, figures/graphs in this case study were made by myself for the purpose of this case study._
